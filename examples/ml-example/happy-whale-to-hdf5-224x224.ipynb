{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Happy Whale Images Converted to HDF5 for Faster Batch Loading"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T16:10:25.767836Z","iopub.status.busy":"2023-05-20T16:10:25.767166Z","iopub.status.idle":"2023-05-20T16:11:04.981255Z","shell.execute_reply":"2023-05-20T16:11:04.980389Z","shell.execute_reply.started":"2023-05-20T16:10:25.767727Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["=> Converting images to hdf5\n","=> Total Images To Process : 20\n"]},{"name":"stderr","output_type":"stream","text":["30it [00:01, 26.84it/s]                        "]},{"name":"stdout","output_type":"stream","text":["=>  Finished Converting images to hdf5\n","=> ========= Converting Test Images ========= <=\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import h5py\n","from PIL import Image\n","import os\n","import numpy as np\n","from tqdm import tqdm\n","import pncpy\n","\n","# paths\n","TRAIN_IMAGES = '../../../exercise/whale-and-dolphin/train_images'\n","TEST_IMAGES = '../../../exercise/whale-and-dolphin/test_images'\n","\n","\n","\n","def list_files(gtdir):\n","    file_list = []\n","    for root, dirs, files in os.walk(gtdir):\n","        for file in files:\n","            file_list.append(os.path.join(root,file))\n","    return file_list\n","\n","def tohdf5(file_list, out_file_path='train_images.hdf5'):\n","    print ('=> Converting images to hdf5')\n","    print ('=> Total Images To Process : {}'.format(len(file_list)))\n","    pbar = tqdm(total=len(file_list))\n","    count = 0\n","    with h5py.File(out_file_path, \"w\") as h5:\n","        for f_ in file_list:\n","            image = Image.open(f_)\n","            if image.mode == 'L':\n","                image = image.convert('RGB')\n","            image = image.resize((224,224))\n","            image = np.array(image)\n","            file_name = f_.split(os.sep)[-1]\n","            #print (file_name, image.shape)\n","            h5.create_dataset(file_name, data=image)\n","            count = count + 1\n","            if count % 10 == 0:\n","                pbar.update(count)\n","    h5.close()\n","    pbar.close()\n","    print('=>  Finished Converting images to hdf5')\n","       \n","# print('=> ========= Converting Train Images ========= <=')\n","file_list = list_files(TRAIN_IMAGES)[:100]\n","tohdf5(file_list,out_file_path='train_images.hdf5')\n","print('=> ========= Converting Test Images ========= <=')\n","# file_list = list_files(TEST_IMAGES)[:100]\n","# tohdf5(file_list,out_file_path='test_images.hdf5')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Example DataLoader and DataSet in PyTorch"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T16:37:12.833228Z","iopub.status.busy":"2023-05-20T16:37:12.832007Z","iopub.status.idle":"2023-05-20T16:37:13.134913Z","shell.execute_reply":"2023-05-20T16:37:13.133712Z","shell.execute_reply.started":"2023-05-20T16:37:12.833164Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["=> Reading HDF5 File...\n","=> Dataset created, image hdf5 file is : ./train_images.hdf5\n","torch.Size([4, 3, 224, 224])\n","tensor([[[-0.7650, -0.6965, -0.6281,  ..., -1.0219, -0.9705, -1.0219],\n","         [-0.5938, -0.5253, -0.4911,  ..., -1.2103, -1.1589, -1.1075],\n","         [-0.5767, -0.5424, -0.5253,  ..., -1.1418, -1.1247, -1.1075],\n","         ...,\n","         [-1.2959, -1.3130, -1.3473,  ..., -1.2788, -1.2617, -1.2617],\n","         [-1.3473, -1.3644, -1.3473,  ..., -1.2788, -1.2617, -1.2788],\n","         [-1.3815, -1.3644, -1.3473,  ..., -1.2274, -1.2274, -1.2617]],\n","\n","        [[ 0.1527,  0.2052,  0.2227,  ..., -0.2675, -0.2500, -0.2325],\n","         [ 0.3452,  0.3803,  0.3978,  ..., -0.4776, -0.4601, -0.4251],\n","         [ 0.3102,  0.3452,  0.3452,  ..., -0.4426, -0.4426, -0.4426],\n","         ...,\n","         [-1.2479, -1.2654, -1.2479,  ..., -1.1954, -1.1779, -1.2129],\n","         [-1.2829, -1.3004, -1.2829,  ..., -1.1954, -1.1779, -1.2129],\n","         [-1.2654, -1.2654, -1.3004,  ..., -1.1604, -1.1779, -1.1604]],\n","\n","        [[ 1.2457,  1.2631,  1.2631,  ...,  0.7925,  0.8797,  0.8797],\n","         [ 1.3154,  1.3328,  1.3328,  ...,  0.5485,  0.6182,  0.6531],\n","         [ 1.2980,  1.3154,  1.3154,  ...,  0.5659,  0.5834,  0.6008],\n","         ...,\n","         [-0.8633, -0.8807, -0.8807,  ..., -0.8284, -0.8110, -0.7936],\n","         [-0.8807, -0.8981, -0.8807,  ..., -0.8284, -0.8110, -0.7936],\n","         [-0.8633, -0.8458, -0.8633,  ..., -0.7936, -0.7936, -0.7936]]])\n","torch.Size([4, 3, 224, 224])\n","tensor([[[-0.6109, -0.6623, -0.6109,  ..., -0.6109, -0.6109, -0.5938],\n","         [-0.5253, -0.6109, -0.6109,  ..., -0.6109, -0.6109, -0.6109],\n","         [-0.4568, -0.5253, -0.7137,  ..., -0.5596, -0.5938, -0.6281],\n","         ...,\n","         [-0.9877, -0.9877, -0.9534,  ..., -0.8335, -0.8678, -0.9020],\n","         [-0.9534, -0.9534, -0.9363,  ..., -0.7993, -0.8164, -0.8335],\n","         [-0.9192, -0.9363, -0.9363,  ..., -0.8335, -0.8335, -0.8678]],\n","\n","        [[-0.6527, -0.7227, -0.6702,  ..., -0.6001, -0.6001, -0.5651],\n","         [-0.5651, -0.6702, -0.6702,  ..., -0.5651, -0.5826, -0.5826],\n","         [-0.5126, -0.6001, -0.7402,  ..., -0.5476, -0.5651, -0.6001],\n","         ...,\n","         [-0.8978, -0.8803, -0.8452,  ..., -0.7577, -0.7752, -0.7927],\n","         [-0.8627, -0.8452, -0.8277,  ..., -0.7227, -0.7227, -0.7227],\n","         [-0.8452, -0.8452, -0.8452,  ..., -0.7402, -0.7577, -0.7752]],\n","\n","        [[-0.3753, -0.4450, -0.4101,  ..., -0.2532, -0.2532, -0.2358],\n","         [-0.3230, -0.4275, -0.4275,  ..., -0.2358, -0.2532, -0.2532],\n","         [-0.2532, -0.3578, -0.4624,  ..., -0.2184, -0.2358, -0.2707],\n","         ...,\n","         [-0.6890, -0.6890, -0.6541,  ..., -0.5147, -0.5147, -0.5495],\n","         [-0.6715, -0.6541, -0.6541,  ..., -0.4624, -0.4450, -0.4973],\n","         [-0.6541, -0.6541, -0.6541,  ..., -0.4973, -0.4973, -0.5321]]])\n","torch.Size([4, 3, 224, 224])\n","tensor([[[-0.3541, -0.3883, -0.4054,  ..., -0.7308, -0.7479, -0.8507],\n","         [-0.4739, -0.5253, -0.5253,  ..., -0.7650, -0.7822, -0.8507],\n","         [-0.5938, -0.6623, -0.6281,  ..., -0.8164, -0.8335, -0.8507],\n","         ...,\n","         [-0.9020, -0.8849, -0.8849,  ..., -0.7650, -0.7308, -0.6281],\n","         [-0.9192, -0.9192, -0.8849,  ..., -0.7137, -0.6623, -0.5767],\n","         [-0.9192, -0.9363, -0.9020,  ..., -0.6623, -0.6281, -0.6281]],\n","\n","        [[ 0.2752,  0.2402,  0.2227,  ..., -0.2500, -0.2675, -0.3550],\n","         [ 0.1352,  0.0826,  0.1001,  ..., -0.2850, -0.2850, -0.3550],\n","         [-0.0049, -0.0574, -0.0399,  ..., -0.3375, -0.3375, -0.3550],\n","         ...,\n","         [-0.4251, -0.4251, -0.4601,  ..., -0.0574, -0.0224,  0.0826],\n","         [-0.4251, -0.4426, -0.4601,  ..., -0.0049,  0.0476,  0.1352],\n","         [-0.4426, -0.4601, -0.4776,  ...,  0.0476,  0.0826,  0.0826]],\n","\n","        [[ 1.0539,  1.0191,  1.0191,  ...,  0.4265,  0.3916,  0.2696],\n","         [ 0.9145,  0.8797,  0.8797,  ...,  0.4091,  0.3742,  0.2696],\n","         [ 0.7576,  0.7228,  0.7402,  ...,  0.3393,  0.3219,  0.2696],\n","         ...,\n","         [ 0.1476,  0.1651,  0.1302,  ...,  0.9319,  0.9842,  1.0888],\n","         [ 0.1651,  0.1476,  0.1302,  ...,  1.0191,  1.0539,  1.1411],\n","         [ 0.1476,  0.1302,  0.1302,  ...,  1.0539,  1.0888,  1.1062]]])\n","torch.Size([4, 3, 224, 224])\n","tensor([[[0.4508, 0.5022, 0.6392,  ..., 0.4337, 0.3823, 0.3481],\n","         [0.4337, 0.4337, 0.5364,  ..., 0.4851, 0.4679, 0.4679],\n","         [0.3481, 0.2796, 0.1254,  ..., 0.5536, 0.5536, 0.5536],\n","         ...,\n","         [0.5707, 0.5536, 0.5193,  ..., 0.0912, 0.0569, 0.0912],\n","         [0.5878, 0.6049, 0.6563,  ..., 0.1426, 0.1254, 0.0912],\n","         [0.1426, 0.1939, 0.2624,  ..., 0.1768, 0.0741, 0.0741]],\n","\n","        [[0.5728, 0.6779, 0.7829,  ..., 0.6078, 0.5903, 0.5378],\n","         [0.5903, 0.6078, 0.6779,  ..., 0.6604, 0.6429, 0.6429],\n","         [0.5203, 0.4503, 0.3277,  ..., 0.7304, 0.7304, 0.7479],\n","         ...,\n","         [0.7304, 0.7129, 0.6604,  ..., 0.2927, 0.2752, 0.3102],\n","         [0.8004, 0.8179, 0.8354,  ..., 0.3803, 0.3452, 0.3102],\n","         [0.3978, 0.4503, 0.4678,  ..., 0.3978, 0.3102, 0.2752]],\n","\n","        [[0.7751, 0.8797, 1.0017,  ..., 0.8448, 0.8274, 0.7576],\n","         [0.7751, 0.8099, 0.8971,  ..., 0.9145, 0.8971, 0.9319],\n","         [0.7054, 0.6531, 0.5311,  ..., 1.0191, 1.0191, 1.0191],\n","         ...,\n","         [0.9494, 0.9319, 0.8797,  ..., 0.5136, 0.5136, 0.5311],\n","         [1.0017, 1.0191, 1.0539,  ..., 0.6182, 0.5659, 0.5659],\n","         [0.5485, 0.6182, 0.6531,  ..., 0.6182, 0.5485, 0.5485]]])\n","torch.Size([4, 3, 224, 224])\n","tensor([[[ 1.1015,  1.1187,  1.1358,  ...,  1.1529,  1.1529,  1.1358],\n","         [ 1.1015,  1.1187,  1.1358,  ...,  1.1529,  1.1529,  1.1358],\n","         [ 1.1015,  1.1187,  1.1358,  ...,  1.1529,  1.1529,  1.1358],\n","         ...,\n","         [-1.1075, -1.0048, -0.8678,  ..., -1.0904, -0.8849, -0.8678],\n","         [-1.0562, -1.0048, -0.8678,  ..., -1.0904, -0.9363, -0.8507],\n","         [-1.0390, -1.0390, -0.9020,  ..., -1.0733, -0.9534, -0.9363]],\n","\n","        [[ 1.6057,  1.6057,  1.5882,  ...,  1.6232,  1.6232,  1.6057],\n","         [ 1.6057,  1.6057,  1.6057,  ...,  1.6232,  1.6232,  1.6057],\n","         [ 1.6057,  1.6057,  1.6057,  ...,  1.6232,  1.6232,  1.6057],\n","         ...,\n","         [-0.3901, -0.3025, -0.1625,  ..., -0.4601, -0.2325, -0.1800],\n","         [-0.3375, -0.3025, -0.1625,  ..., -0.4776, -0.2675, -0.1625],\n","         [-0.3200, -0.3200, -0.1800,  ..., -0.4426, -0.2850, -0.2325]],\n","\n","        [[ 2.2391,  2.2391,  2.2217,  ...,  2.2566,  2.2566,  2.2391],\n","         [ 2.2391,  2.2391,  2.2391,  ...,  2.2566,  2.2566,  2.2391],\n","         [ 2.2391,  2.2391,  2.2391,  ...,  2.2566,  2.2566,  2.2391],\n","         ...,\n","         [ 0.5659,  0.6531,  0.7925,  ...,  0.4439,  0.6879,  0.7228],\n","         [ 0.6182,  0.6531,  0.8099,  ...,  0.4091,  0.6705,  0.7576],\n","         [ 0.6008,  0.6182,  0.7751,  ...,  0.4439,  0.6356,  0.6705]]])\n"]}],"source":["import torch\n","from torchvision import transforms\n","from torch.utils.data import DataLoader, Dataset\n","import pandas as pd\n","\n","\n","TRAIN_CSV = '../../../exercise/whale-and-dolphin/train.csv'\n","TEST_CSV = '.../../../exercise/happy-whale-and-dolphin/sample_submission.csv'\n","img_lists = [file.split('/')[-1] for file in file_list]\n","\n","# Change accordingly \n","# if input\n","#DATASET_ROOT = '../input/happy-whale-to-hdf5-224x224'\n","\n","# if output\n","DATASET_ROOT = './'\n","\n","# Read CSV to DataFrame\n","train_df = pd.read_csv(TRAIN_CSV)\n","\n","# Filter based on files\n","train_df = train_df[train_df.image.isin(img_lists)]\n","\n","# Train Transforms\n","train_transforms  = transforms.Compose([\n","                transforms.ToTensor(),\n","                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n","        ])\n","\n","\n","# Label Encoder\n","def get_label_encoder_decoder(unique_values):\n","    label_encoder = {}\n","    label_decoder = {}\n","    for idx, label in enumerate(unique_values):\n","        label_encoder[label] = idx\n","        label_decoder[idx] = label\n","    return label_encoder, label_decoder\n","\n","label_encoder_ind_id, label_decoder_ind_id = get_label_encoder_decoder(train_df['individual_id'].unique())\n","\n","# torch dataloader\n","class DolphinWhaleDatasetH5(Dataset):\n","    \n","    def __init__(self, root_dir, data_frame, is_train=True, transforms=None):\n","    \n","        self.image_names = data_frame['image'].values\n","        self.is_train = is_train\n","        if is_train:\n","            self.labels = data_frame['individual_id'].values\n","        else:\n","            self.labels = [-1] *  len(self.image_names)\n","           \n","        self.transforms = transforms\n","        print ('=> Reading HDF5 File...')\n","        hdf5_path = os.path.join(root_dir,'{}_images.hdf5'.format('train' if is_train else 'test'))\n","        self.h5 = h5py.File(hdf5_path,'r')\n","        print('=> Dataset created, image hdf5 file is : {}'.format(hdf5_path))\n","        \n","    def __len__(self):\n","        return len(self.image_names)\n","    \n","    def fetch_item_train(self,idx):\n","        \n","        # image name\n","        image_name = self.image_names[idx]\n","       \n","        # read image \n","        image = np.array(self.h5[image_name])\n","        \n","        # fetch and encode label\n","        label = label_encoder_ind_id[self.labels[idx]]\n","       \n","        if self.transforms:\n","            image = self.transforms(image)\n","        \n","        return {'image':image,\n","                'label':label,}\n","    \n","    def fetch_item_test(self,idx):\n","        image_name = self.image_names[idx]\n","       \n","        # read image \n","        image = np.array(self.h5[image_name])  \n","       \n","        if self.transforms:\n","            image = self.transforms(image)\n","        \n","        return {'image':image,\n","                'image_name':image_name}\n","    \n","    def __getitem__(self, index):\n","        if self.is_train:\n","            return self.fetch_item_train(index)\n","        else:\n","            return self.fetch_item_test(index)\n","    \n","\n","    \n","# Training and Validation Dataset\n","dataset = DolphinWhaleDatasetH5(DATASET_ROOT,train_df,is_train=True, transforms=train_transforms)\n","\n","train_loader = DataLoader(\n","    dataset, batch_size=4, num_workers=1)\n","\n","for batch_idx, sample_ in enumerate(train_loader):\n","    inputs = sample_['image']  \n","    print(inputs.shape)\n","    print(inputs[0])\n","    if batch_idx > 10:\n","        break\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"}},"nbformat":4,"nbformat_minor":4}
