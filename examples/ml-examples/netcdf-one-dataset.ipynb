{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Happy Whale Images Converted to netcdf for Faster Batch Loading"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T16:10:25.767836Z","iopub.status.busy":"2023-05-20T16:10:25.767166Z","iopub.status.idle":"2023-05-20T16:11:04.981255Z","shell.execute_reply":"2023-05-20T16:11:04.980389Z","shell.execute_reply.started":"2023-05-20T16:10:25.767727Z"},"trusted":true},"outputs":[],"source":["import h5py\n","from PIL import Image\n","import os\n","import numpy as np\n","from tqdm import tqdm\n","import pncpy\n","import pandas as pd\n","\n","# paths\n","TRAIN_IMAGES = '../../../exercise/whale-and-dolphin/train_images'\n","TEST_IMAGES = '../../../exercise/whale-and-dolphin/test_images'\n","\n","\n","\n","def list_files(gtdir):\n","    file_list = []\n","    for root, dirs, files in os.walk(gtdir):\n","        for file in files:\n","            file_list.append(os.path.join(root,file))\n","    return file_list\n","\n","def tonetcdf(gtdir, out_file_path, df):\n","    print ('=> Converting images to netcdf')\n","    images_names = df.image.values\n","    print ('=> Total Images To Process : {}'.format(len(images_names)))\n","    pbar = tqdm(total=len(images_names))\n","    count = 0\n","    \n","    with pncpy.File(out_file_path, mode = \"w\", format = \"64BIT_DATA\") as fnc:\n","        dim_y = fnc.def_dim(\"Y\", 224)\n","        dim_x = fnc.def_dim(\"X\", 224)\n","        dim_rgb = fnc.def_dim(\"RGB\", 3)\n","        dim_n = fnc.def_dim(\"img_idx\", len(images_names))\n","        var = fnc.def_var(\"images\", pncpy.NC_UBYTE, (dim_n, dim_y, dim_x, dim_rgb))\n","        fnc.enddef()\n","        for k, img_name in enumerate(images_names):\n","            f_ = os.path.join(gtdir, img_name)\n","            image = Image.open(f_)\n","            if image.mode == 'L':\n","                image = image.convert('RGB')\n","            image = image.resize((224,224))\n","            image = np.array(image)\n","            var[k] = image \n","            count = count + 1\n","            if count % 10 == 0:\n","                pbar.update(count)\n","\n","    pbar.close()\n","    print('=>  Finished Converting images to netcdf')\n","       \n","# print('=> ========= Converting Train Images ========= <=')\n","TRAIN_CSV = '../../../exercise/whale-and-dolphin/train.csv'\n","TEST_CSV = '.../../../exercise/happy-whale-and-dolphin/sample_submission.csv'\n","train_df = pd.read_csv(TRAIN_CSV)\n","tonetcdf(TRAIN_IMAGES,'train_images.nc', train_df)\n","print('=> ========= Converting Test Images ========= <=')\n","# file_list = list_files(TEST_IMAGES)[:100]\n","# tonc(file_list,out_file_path='test_images.nc')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Example DataLoader and DataSet in PyTorch with PnetCDF-python"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T16:37:12.833228Z","iopub.status.busy":"2023-05-20T16:37:12.832007Z","iopub.status.idle":"2023-05-20T16:37:13.134913Z","shell.execute_reply":"2023-05-20T16:37:13.133712Z","shell.execute_reply.started":"2023-05-20T16:37:12.833164Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torchvision import transforms\n","from torch.utils.data import DataLoader, Dataset\n","import pandas as pd\n","\n","\n","TRAIN_CSV = '../../../exercise/whale-and-dolphin/train.csv'\n","TEST_CSV = '.../../../exercise/whale-and-dolphin/sample_submission.csv'\n","# img_lists = [file.split('/')[-1] for file in file_list]\n","\n","# Change accordingly \n","# if input\n","#DATASET_ROOT = '../input/happy-whale-to-hdf5-224x224'\n","\n","# if output\n","DATASET_ROOT = './'\n","\n","# Read CSV to DataFrame\n","train_df = pd.read_csv(TRAIN_CSV)\n","\n","\n","# Train Transforms\n","train_transforms  = transforms.Compose([\n","                transforms.ToTensor(),\n","                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n","        ])\n","\n","\n","# Label Encoder\n","def get_label_encoder_decoder(unique_values):\n","    label_encoder = {}\n","    label_decoder = {}\n","    for idx, label in enumerate(unique_values):\n","        label_encoder[label] = idx\n","        label_decoder[idx] = label\n","    return label_encoder, label_decoder\n","\n","label_encoder_ind_id, label_decoder_ind_id = get_label_encoder_decoder(train_df['individual_id'].unique())\n","\n","# torch dataloader\n","class DolphinWhaleDatasetNetCDF(Dataset):\n","    \n","    def __init__(self, root_dir, data_frame, is_train=True, transforms=None):\n","    \n","        self.image_names = data_frame['image'].values\n","        self.is_train = is_train\n","        if is_train:\n","            self.labels = data_frame['individual_id'].values\n","        else:\n","            self.labels = [-1] *  len(self.image_names)\n","           \n","        self.transforms = transforms\n","        print ('=> Reading NetCDF File...')\n","        nc_path = os.path.join(root_dir,'{}_images.nc'.format('train' if is_train else 'test'))\n","        self.nc = pncpy.File(nc_path,'r')\n","        print('=> Dataset created, image nc file is : {}'.format(nc_path))\n","        \n","    def __len__(self):\n","        return len(self.image_names)\n","    \n","    def fetch_item_train(self,idx):\n","        \n","        # image name\n","        image_name = self.image_names[idx]\n","       \n","        # read image \n","        image = np.array(self.nc.variables['images'][idx])\n","        \n","        # fetch and encode label\n","        label = label_encoder_ind_id[self.labels[idx]]\n","       \n","        if self.transforms:\n","            image = self.transforms(image)\n","        \n","        return {'image':image,\n","                'label':label,}\n","    \n","    def fetch_item_test(self,idx):\n","        image_name = self.image_names[idx]\n","       \n","        # read image \n","        image = np.array(self.nc.variables['images'][idx])\n","       \n","        if self.transforms:\n","            image = self.transforms(image)\n","        \n","        return {'image':image,\n","                'image_name':image_name}\n","    \n","    def __getitem__(self, index):\n","        if self.is_train:\n","            return self.fetch_item_train(index)\n","        else:\n","            return self.fetch_item_test(index)\n","    \n","\n","    \n","# Training and Validation Dataset\n","dataset = DolphinWhaleDatasetNetCDF(DATASET_ROOT,train_df,is_train=True, transforms=train_transforms)\n","\n","train_loader = DataLoader(\n","    dataset, batch_size=4, num_workers=4)\n","print(len(train_loader))\n","for batch_idx, sample_ in enumerate(train_loader):\n","    inputs = sample_['image']  \n","    print(inputs.shape)\n","    print(inputs[0])\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"}},"nbformat":4,"nbformat_minor":4}
